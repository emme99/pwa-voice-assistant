# Developer Guide (README-DEV.md)

This document is intended for developers who want to contribute to the **PWA Voice Assistant** project. Here you will find an overview of the architecture, file structure, and instructions for the development setup.

## üìÇ Project Structure

```
pwa-voice-assistant/
‚îú‚îÄ‚îÄ client/                     # Frontend (PWA)
‚îÇ   ‚îú‚îÄ‚îÄ app.js                  # Main logic: WebSocket, UI, audio handling
‚îÇ   ‚îú‚îÄ‚îÄ wake-word-processor.js  # AudioWorklet for audio processing and ONNX interference
‚îÇ   ‚îú‚îÄ‚îÄ sw.js                   # Service Worker (caching and offline handling)
‚îÇ   ‚îú‚îÄ‚îÄ styles.css              # CSS Styles
‚îÇ   ‚îú‚îÄ‚îÄ index.html              # UI Entry point
‚îÇ   ‚îú‚îÄ‚îÄ overlay.html            # Lightweight version for iframe/overlay
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # ONNX models for wake word detection
‚îÇ   ‚îî‚îÄ‚îÄ libs/                   # External libraries (onnxruntime-web)
‚îÇ
‚îú‚îÄ‚îÄ server/                     # Backend (Python)
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # Server entry point
‚îÇ   ‚îú‚îÄ‚îÄ websocket_server.py     # WebSocket Server to communicate with PWA Client
‚îÇ   ‚îú‚îÄ‚îÄ wyoming_server.py       # Wyoming Protocol Server to communicate with Home Assistant
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml             # Runtime configuration
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ run-pwa-voice-assistant.sh  # Helper script for Docker startup
‚îú‚îÄ‚îÄ analyze_wav.py              # Utility script for debugging WAV audio files
‚îî‚îÄ‚îÄ README.md                   # End-user documentation
```

## üèó Architecture

The system acts as a "bridge" between the browser and Home Assistant:

1.  **Frontend (Client)**:
    *   Captures audio from the microphone.
    *   Performs Wake Word detection **locally** using `onnxruntime-web` (WebAssembly).
    *   When the wake word is detected, it sends raw audio (PCM 16-bit 16kHz) to the server via WebSocket.
    *   Receives audio streams (TTS) to play and status messages.

2.  **Backend (Server)**:
    *   **WebSocket Server** (`port 8765`): Receives commands and audio from the PWA.
    *   **Wyoming Server** (`port 10400`): Acts as a Wyoming "Satellite". Forwards audio to Home Assistant and receives TTS/STT commands from Home Assistant.
    *   Connects the two worlds: Wake Word Event (Client) -> Trigger Pipeline (HA).

## üß© Key Components

### Client (`client/`)
-   **`app.js`**: Manages the state machine (Idle, Listening, Processing). Handles automatic socket reconnection and the user interface.
-   **`wake-word-processor.js`**: Runs in a separate thread (AudioWorklet). Accumulates audio buffers, calculates features (Melspectrogram), and sends tensors to the ONNX model.
-   **`sw.js`**: Cache-first strategy to enable offline functionality and reduce loading times.

### Server (`server/`)
-   **`wyoming_server.py`**: Implements the Wyoming protocol specifications. Handles events like `run-pipeline`, `audio-start`, `audio-chunk`.
-   **`websocket_server.py`**: Handles multiple connections from browser clients. Forwards binary audio chunks directly to the Wyoming server.

## üõ† Local Development

### Prerequisites
-   Python 3.9+
-   Node.js (optional, only for model conversion or managing npm packages if introduced)

### Setup

1.  **Clone the repo**:
    ```bash
    git clone https://github.com/emme99/pwa-voice-assistant.git
    cd pwa-voice-assistant
    ```

2.  **Server**:
    Create a virtual environment and install dependencies:
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    pip install -r server/requirements.txt
    ```

3.  **Configuration**:
    Copy the example file:
    ```bash
    cp server/config.example.yaml server/config.yaml
    ```

4.  **Start**:
    ```bash
    python3 server/main.py
    ```
    The server will listen on `0.0.0.0:8765` (WS) and `0.0.0.0:10400` (Wyoming).

5.  **Client**:
    No build needed! The Python server directly serves the `client/` folder.
    Open your browser at: `http://localhost:8765`

## üêõ Debugging

-   **Client**: Use Chrome DevTools (Console). Click 5 times on the "Connected" status in the UI to perform an on-screen debug log.
-   **Server**: Logs are printed to stdout. Set `logging.level: DEBUG` in `config.yaml` for more verbosity.
-   **Audio**: Use `analyze_wav.py` to inspect `.wav` files saved in the `server/` folder if audio dump is enabled.

## ü§ù Contributing

Feel free to open Issues or Pull Requests. For substantial architecture changes, please open a discussion first.
